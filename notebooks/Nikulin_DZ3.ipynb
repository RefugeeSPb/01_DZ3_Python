{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "aca0353b",
      "metadata": {
        "id": "aca0353b"
      },
      "source": [
        "# Домашнее задание 3. Парсинг, Git и тестирование на Python\n",
        "\n",
        "**Цели задания:**\n",
        "\n",
        "* Освоить базовые подходы к web-scraping с библиотеками `requests` и `BeautisulSoup`: навигация по страницам, извлечение HTML-элементов, парсинг.\n",
        "* Научиться автоматизировать задачи с использованием библиотеки `schedule`.\n",
        "* Попрактиковаться в использовании Git и оформлении проектов на GitHub.\n",
        "* Написать и запустить простые юнит-тесты с использованием `pytest`.\n",
        "\n",
        "\n",
        "В этом домашнем задании вы разработаете систему для автоматического сбора данных о книгах с сайта [Books to Scrape](http://books.toscrape.com). Нужно реализовать функции для парсинга всех страниц сайта, извлечения информации о книгах, автоматического ежедневного запуска задачи и сохранения результата.\n",
        "\n",
        "Важной частью задания станет оформление проекта: вы создадите репозиторий на GitHub, оформите `README.md`, добавите артефакты (код, данные, отчеты) и напишете базовые тесты на `pytest`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "K3JMV0qwmA_q",
      "metadata": {
        "id": "K3JMV0qwmA_q"
      },
      "outputs": [],
      "source": [
        "! pip install -q schedule pytest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "873d4904",
      "metadata": {
        "id": "873d4904"
      },
      "outputs": [],
      "source": [
        "# Библиотеки, которые могут вам понадобиться\n",
        "# При необходимости расширяйте список\n",
        "import datetime\n",
        "import time\n",
        "import requests\n",
        "import schedule\n",
        "import json\n",
        "import pytest\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "unTvsWaegHdj",
      "metadata": {
        "id": "unTvsWaegHdj"
      },
      "source": [
        "## Задание 1. Сбор данных об одной книге (20 баллов)\n",
        "\n",
        "В этом задании мы начнем подготовку скрипта для парсинга информации о книгах со страниц каталога сайта [Books to Scrape](https://books.toscrape.com/).\n",
        "\n",
        "Для начала реализуйте функцию `get_book_data`, которая будет получать данные о книге с одной страницы (например, с [этой](http://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html)). Соберите всю информацию, включая название, цену, рейтинг, количество в наличии, описание и дополнительные характеристики из таблицы Product Information. Результат достаточно вернуть в виде словаря.\n",
        "\n",
        "**Не забывайте про соблюдение PEP-8** — помимо качественно написанного кода важно также документировать функции по стандарту:\n",
        "* кратко описать, что она делает и для чего нужна;\n",
        "* какие входные аргументы принимает, какого они типа и что означают по смыслу;\n",
        "* аналогично описать возвращаемые значения.\n",
        "\n",
        "*P. S. Состав, количество аргументов функции и тип возвращаемого значения можете менять как вам удобно. То, что написано ниже в шаблоне — лишь пример.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "UfD2vAjHkEoS",
      "metadata": {
        "id": "UfD2vAjHkEoS"
      },
      "outputs": [],
      "source": [
        "def get_book_data(book_url: str) -> dict:\n",
        "    \"\"\"\n",
        "    Функция для получения данных о книге по url\n",
        "\n",
        "    Функция должна возвращать определенную информацию по книге:\n",
        "    - Название\n",
        "    - Цена\n",
        "    - Рейтинг\n",
        "    - Количество в наличии\n",
        "    - Описание\n",
        "    - Дополнительные характеристики\n",
        "\n",
        "    Функция должна возвращать словарь в формате словаря:\n",
        "    {\n",
        "        'name': 'Название книги',\n",
        "        'price euro': 'Цена',\n",
        "        'rating': 'Рейтинг',\n",
        "        'stock': 'Количество в наличии',\n",
        "        'description': 'Описание',\n",
        "        'Product Information': 'Дополнительные характеристики'  --Данные список будет выводится по всем возможным дополнительным параметрам\n",
        "     }\n",
        "\n",
        "     аргументы: ссылка на книгу в формате str\n",
        "\n",
        "      методы:\n",
        "      pass\n",
        "\n",
        "     return: словарь с данными о книге\n",
        "\n",
        "    >>>book_url = \"http://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html\"\n",
        "    >>>get_book_data(book_url)\n",
        "\n",
        "        {'name': 'A Light in the Attic',\n",
        "        'price euro': 51.77,\n",
        "        'rating': 3.0,\n",
        "        'stock': 22,\n",
        "        'Decription': \"It's hard to imagine a world without A Light in the Attic. This now-classic collection of poetry and drawings from Shel Silverstein celebrates its 20th anniversary with this special edition. Silverstein's humorous and creative verse can amuse the dowdiest of readers. Lemon-faced adults and fidgety kids sit still and read these rhythmic words and laugh and smile and love th It's hard to imagine a world without A Light in the Attic. This now-classic collection of poetry and drawings from Shel Silverstein celebrates its 20th anniversary with this special edition. Silverstein's humorous and creative verse can amuse the dowdiest of readers. Lemon-faced adults and fidgety kids sit still and read these rhythmic words and laugh and smile and love that Silverstein. Need proof of his genius? RockabyeRockabye baby, in the treetopDon't you know a treetopIs no safe place to rock?And who put you up there,And your cradle, too?Baby, I think someone down here'sGot it in for you. Shel, you never sounded so good. ...more\",\n",
        "        'UPC': 'a897fe39b1053632',\n",
        "        'Product Type': 'Books',\n",
        "        'Tax': 0.0,\n",
        "        'Number of reviews': '0'}\n",
        "            \"\"\"\n",
        "\n",
        "    # НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
        "    # Создаем словарь с ключами\n",
        "    book_dict = {}\n",
        "    # Перевод рейтинга в числа\n",
        "    rating_book = {\"One\": 1, \"Two\": 2, \"Three\": 3, \"Four\": 4, \"Five\": 5}\n",
        "    # список дополнительных данных, которые мы не выгружаем, так как уже подобные есть\n",
        "    book_exception_description = {\n",
        "        \"Price (excl. tax)\",\n",
        "        \"Price (incl. tax)\",\n",
        "        \"Availability\",\n",
        "    }\n",
        "\n",
        "    # Получаем данные о книге. Проверяем подключение\n",
        "    try:\n",
        "        req_book = requests.get(book_url)\n",
        "        req_book.raise_for_status()\n",
        "        timeout = (7, 11)\n",
        "    except req_book.HTTPError as err:\n",
        "        return print(f\"Возникла ошибка: {err}\")  # надо ли вообще?\n",
        "\n",
        "    # Имеем HTML формат. Так как мы парсим опредлеленный сайт, то мы не проверяем тип данных\n",
        "    # print(req_book.headers[\"Content-Type\"])\n",
        "\n",
        "    # Проверяем кодировку\n",
        "    # current_encoding = req_book.encoding\n",
        "    # print(f\"Текущая кодировка: {current_encoding}\")\n",
        "    req_book.encoding = \"utf-8\"\n",
        "\n",
        "    # Парсим данные по html\n",
        "    req_book_html = BeautifulSoup(req_book.text, \"html.parser\")\n",
        "\n",
        "    # 1. Заранее определяем, что h1 - название книги. Ищем и вставляем название в словарь\n",
        "    book_name = req_book_html.find(\"h1\").text.strip()\n",
        "    book_dict.update({\"name\": str(book_name)})\n",
        "\n",
        "    # 2. Заранее определяем, что p - цена книги. Ищем и вставляем название в словарь\n",
        "    book_price = req_book_html.find(\"p\", class_=\"price_color\").text.strip()[1:]\n",
        "    book_dict.update({\"price euro\": float(book_price)})\n",
        "\n",
        "    # 3. Рейтинг (ищем элемент с классом star-rating и извлекаем подкласс)\n",
        "    rating_element = req_book_html.find(\"p\", class_=\"star-rating\")\n",
        "    rating_classes = list(rating_element.get(\"class\", []))  # type: ignore\n",
        "    book_dict.update({\"rating\": float(rating_book.get(rating_classes[1]))})  # type: ignore\n",
        "\n",
        "    # 4. Остатки (ищем элемент с классом p - instock availability извлекаем позиции чисел)\n",
        "    stock_element_start = (\n",
        "        req_book_html.find(\"p\", class_=\"instock availability\").text.strip().find(\"(\")\n",
        "        + 1\n",
        "    )\n",
        "    stock_element_end = (\n",
        "        req_book_html.find(\"p\", class_=\"instock availability\")\n",
        "        .text.strip()\n",
        "        .find(\" available\")\n",
        "    )\n",
        "    # print(req_book_html.find(\"p\", class_=\"instock availability\").text.strip()[stock_element_start:stock_element_end])\n",
        "    book_dict.update(\n",
        "        {\n",
        "            \"stock\": int(\n",
        "                req_book_html.find(\"p\", class_=\"instock availability\").text.strip()[\n",
        "                    stock_element_start:stock_element_end\n",
        "                ]\n",
        "            )\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # 5. Описание (ищем элемент с классом star-rating и извлекаем подкласс)\n",
        "    try:\n",
        "        description_element = (\n",
        "            req_book_html.find(\"div\", id=\"product_description\")\n",
        "            .find_next(\"p\")\n",
        "            .text.strip()\n",
        "        )\n",
        "        book_dict.update({\"Decription\": str(description_element)})\n",
        "    except:\n",
        "        book_dict.update({\"Decription\": \"No description\"})\n",
        "\n",
        "    # 6. Product Information. По всем строкам table/tr ищем по th - key, по td - value.\n",
        "    product_info_element_key = (\n",
        "        req_book_html.find(\"h2\", string=\"Product Information\")\n",
        "        .find_next(\"table\")\n",
        "        .find_all(\"tr\")\n",
        "    )\n",
        "\n",
        "    for row in product_info_element_key:\n",
        "        try:\n",
        "            key = row.find(\"th\").text.strip()\n",
        "            if key in book_exception_description:\n",
        "                continue\n",
        "            value = row.find(\"td\").text.strip()\n",
        "            #\n",
        "            book_dict[key] = value if key != \"Tax\" else float(value[1:])\n",
        "        except:\n",
        "            continue\n",
        "        # pass\n",
        "\n",
        "    return book_dict\n",
        "    # КОНЕЦ ВАШЕГО РЕШЕНИЯ\n",
        "\n",
        "\n",
        "# Используйте для самопроверки\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "moRSO9Itp1LT",
      "metadata": {
        "id": "moRSO9Itp1LT"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'name': 'A Light in the Attic',\n",
              " 'price euro': 51.77,\n",
              " 'rating': 3.0,\n",
              " 'stock': 22,\n",
              " 'Decription': \"It's hard to imagine a world without A Light in the Attic. This now-classic collection of poetry and drawings from Shel Silverstein celebrates its 20th anniversary with this special edition. Silverstein's humorous and creative verse can amuse the dowdiest of readers. Lemon-faced adults and fidgety kids sit still and read these rhythmic words and laugh and smile and love th It's hard to imagine a world without A Light in the Attic. This now-classic collection of poetry and drawings from Shel Silverstein celebrates its 20th anniversary with this special edition. Silverstein's humorous and creative verse can amuse the dowdiest of readers. Lemon-faced adults and fidgety kids sit still and read these rhythmic words and laugh and smile and love that Silverstein. Need proof of his genius? RockabyeRockabye baby, in the treetopDon't you know a treetopIs no safe place to rock?And who put you up there,And your cradle, too?Baby, I think someone down here'sGot it in for you. Shel, you never sounded so good. ...more\",\n",
              " 'UPC': 'a897fe39b1053632',\n",
              " 'Product Type': 'Books',\n",
              " 'Tax': 0.0,\n",
              " 'Number of reviews': '0'}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Используйте для самопроверки\n",
        "book_url = \"http://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html\"\n",
        "get_book_data(book_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "u601Q4evosq6",
      "metadata": {
        "id": "u601Q4evosq6"
      },
      "source": [
        "## Задание 2. Сбор данных обо всех книгах (20 баллов)\n",
        "\n",
        "Создайте функцию `scrape_books`, которая будет проходиться по всем страницам из каталога (вида `http://books.toscrape.com/catalogue/page-{N}.html`) и осуществлять парсинг всех страниц в цикле, используя ранее написанную `get_book_data`.\n",
        "\n",
        "Добавьте аргумент-флаг, который будет отвечать за сохранение результата в файл: если он будет равен `True`, то информация сохранится в ту же папку в файл `books_data.txt`; иначе шаг сохранения будет пропущен.\n",
        "\n",
        "**Также не забывайте про соблюдение PEP-8**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "kk78l6oDkdxl",
      "metadata": {
        "id": "kk78l6oDkdxl"
      },
      "outputs": [],
      "source": [
        "def scrape_books(is_save: bool):\n",
        "    \"\"\"\n",
        "    МЕСТО ДЛЯ ДОКУМЕНТАЦИИ\n",
        "    \"\"\"\n",
        "\n",
        "    # НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
        "    # http://books.toscrape.com/catalogue/page-{N}.html\n",
        "    # http://books.toscrape.com/catalogue/page-1.html\n",
        "    # http://books.toscrape.com/catalogue/page-51.html     51 страница - 404\n",
        "\n",
        "    # Стартуем с первой страницы\n",
        "    pages_site = 1\n",
        "    url_site = f\"http://books.toscrape.com/catalogue/page-{pages_site}.html\"\n",
        "    book_list=[]\n",
        "    # Пока не выпадем в ошибку\n",
        "    while True:\n",
        "    #while pages_site <= 3:\n",
        "        req_pages = requests.get(url_site)\n",
        "        # print(url_site)\n",
        "        timeout = (7, 11)\n",
        "        # проверка на ошибку\n",
        "        if req_pages.status_code == 404:\n",
        "            break\n",
        "\n",
        "        req_pages.encoding = \"utf-8\"\n",
        "        req_pages_html = BeautifulSoup(req_pages.text, \"html.parser\")\n",
        "        # print(req_pages_html.prettify())\n",
        "        req_pages_html_find = req_pages_html.find(\"ol\", class_=\"row\").find_all(\n",
        "            \"article\", class_=\"product_pod\"\n",
        "        )\n",
        "        # print(req_pages_html_find)\n",
        "        book_i = 1\n",
        "        #book_list = []\n",
        "        for book_pages in req_pages_html_find:\n",
        "            book_url = book_pages.find(\"a\").get(\"href\")\n",
        "            #print(f\"Page:{pages_site}, №{book_i}. URL: {book_url}\")\n",
        "            percent_time = ((pages_site-1)*20+book_i)/(50*20)*100\n",
        "            print(f\"{percent_time:.2f}%\", end=\"\\r\", flush=True)\n",
        "            book_list.append(\n",
        "                get_book_data(f\"http://books.toscrape.com/catalogue/{book_url}\")\n",
        "            )\n",
        "            book_i += 1\n",
        "\n",
        "        # print(book_list)\n",
        "\n",
        "        pages_site += 1\n",
        "        url_site = f\"http://books.toscrape.com/catalogue/page-{pages_site}.html\"\n",
        "\n",
        "\n",
        "    if is_save:\n",
        "        with open(\"books_data.txt\", \"w\") as f:\n",
        "            f.write(\"\")\n",
        "        for book in book_list:\n",
        "            with open(\"books_data.txt\", \"a\") as f:\n",
        "                json.dump(book, f, indent=4)\n",
        "\n",
        "    print(datetime.datetime.now())\n",
        "    return book_list\n",
        "\n",
        "\n",
        "# scrape_books(is_save=True)\n",
        "# КОНЕЦ ВАШЕГО РЕШЕНИЯ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "Bt7mrXcbkj5Q",
      "metadata": {
        "id": "Bt7mrXcbkj5Q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.40%\r"
          ]
        },
        {
          "ename": "UnboundLocalError",
          "evalue": "cannot access local variable 'req_book' where it is not associated with a value",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 58\u001b[39m, in \u001b[36mget_book_data\u001b[39m\u001b[34m(book_url)\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     req_book = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbook_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m     req_book.raise_for_status()\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\03_IT\\01_Scripts\\01_DZ3_Python\\dz3_venv\\Lib\\site-packages\\requests\\api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m:rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\03_IT\\01_Scripts\\01_DZ3_Python\\dz3_venv\\Lib\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\03_IT\\01_Scripts\\01_DZ3_Python\\dz3_venv\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\03_IT\\01_Scripts\\01_DZ3_Python\\dz3_venv\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\03_IT\\01_Scripts\\01_DZ3_Python\\dz3_venv\\Lib\\site-packages\\requests\\adapters.py:644\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\03_IT\\01_Scripts\\01_DZ3_Python\\dz3_venv\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\03_IT\\01_Scripts\\01_DZ3_Python\\dz3_venv\\Lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\03_IT\\01_Scripts\\01_DZ3_Python\\dz3_venv\\Lib\\site-packages\\urllib3\\connection.py:565\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m565\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\http\\client.py:1430\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1429\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1430\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1431\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\http\\client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\http\\client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\socket.py:719\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[31mUnboundLocalError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Проверка работоспособности функции\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m res = \u001b[43mscrape_books\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_save\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Допишите ваши аргументы\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#res = scrape_books(is_save = False)  # Допишите ваши аргументы\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(res), \u001b[38;5;28mlen\u001b[39m(res))  \u001b[38;5;66;03m# и проверки\u001b[39;00m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 40\u001b[39m, in \u001b[36mscrape_books\u001b[39m\u001b[34m(is_save)\u001b[39m\n\u001b[32m     37\u001b[39m     percent_time = ((pages_site-\u001b[32m1\u001b[39m)*\u001b[32m20\u001b[39m+book_i)/(\u001b[32m50\u001b[39m*\u001b[32m20\u001b[39m)*\u001b[32m100\u001b[39m\n\u001b[32m     38\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpercent_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33m\"\u001b[39m, end=\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[33m\"\u001b[39m, flush=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     39\u001b[39m     book_list.append(\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m         \u001b[43mget_book_data\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhttp://books.toscrape.com/catalogue/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mbook_url\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m     )\n\u001b[32m     42\u001b[39m     book_i += \u001b[32m1\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# print(book_list)\u001b[39;00m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 61\u001b[39m, in \u001b[36mget_book_data\u001b[39m\u001b[34m(book_url)\u001b[39m\n\u001b[32m     59\u001b[39m     req_book.raise_for_status()\n\u001b[32m     60\u001b[39m     timeout = (\u001b[32m7\u001b[39m, \u001b[32m11\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[43mreq_book\u001b[49m.HTTPError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mВозникла ошибка: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# надо ли вообще?\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# Имеем HTML формат. Так как мы парсим опредлеленный сайт, то мы не проверяем тип данных\u001b[39;00m\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# print(req_book.headers[\"Content-Type\"])\u001b[39;00m\n\u001b[32m     66\u001b[39m \n\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# Проверяем кодировку\u001b[39;00m\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# current_encoding = req_book.encoding\u001b[39;00m\n\u001b[32m     69\u001b[39m \u001b[38;5;66;03m# print(f\"Текущая кодировка: {current_encoding}\")\u001b[39;00m\n",
            "\u001b[31mUnboundLocalError\u001b[39m: cannot access local variable 'req_book' where it is not associated with a value"
          ]
        }
      ],
      "source": [
        "# Проверка работоспособности функции\n",
        "res = scrape_books(is_save=True)  # Допишите ваши аргументы\n",
        "#res = scrape_books(is_save = False)  # Допишите ваши аргументы\n",
        "print(type(res), len(res))  # и проверки"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "z5fd728nl8a8",
      "metadata": {
        "id": "z5fd728nl8a8"
      },
      "source": [
        "## Задание 3. Настройка регулярной выгрузки (10 баллов)\n",
        "\n",
        "Настройте автоматический запуск функции сбора данных каждый день в 19:00.\n",
        "Для автоматизации используйте библиотеку `schedule`. Функция должна запускаться в указанное время и сохранять обновленные данные в текстовый файл.\n",
        "\n",
        "\n",
        "\n",
        "Бесконечный цикл должен обеспечивать постоянное ожидание времени для запуска задачи и выполнять ее по расписанию. Однако чтобы не перегружать систему, стоит подумать о том, чтобы выполнять проверку нужного времени не постоянно, а раз в какой-то промежуток. В этом вам может помочь `time.sleep(...)`.\n",
        "\n",
        "Проверьте работоспособность кода локально на любом времени чч:мм.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SajRRCj4n8BZ",
      "metadata": {
        "id": "SajRRCj4n8BZ"
      },
      "outputs": [],
      "source": [
        "# НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
        "\n",
        "schedule.every().day.at(\"19:00\").do(scrape_books, is_save=True)\n",
        "hours_sleep = 1\n",
        "while True:\n",
        "    schedule.run_pending()\n",
        "    time.sleep(60)\n",
        "# КОНЕЦ ВАШЕГО РЕШЕНИЯ"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XFiPtEyaoLxq",
      "metadata": {
        "id": "XFiPtEyaoLxq"
      },
      "source": [
        "## Задание 4. Написание автотестов (15 баллов)\n",
        "\n",
        "Создайте минимум три автотеста для ключевых функций парсинга — например, `get_book_data` и `scrape_books`. Идеи проверок (можете использовать свои):\n",
        "\n",
        "* данные о книге возвращаются в виде словаря с нужными ключами;\n",
        "* список ссылок или количество собранных книг соответствует ожиданиям;\n",
        "* значения отдельных полей (например, `title`) корректны.\n",
        "\n",
        "Оформите тесты в отдельном скрипте `tests/test_scraper.py`, используйте библиотеку `pytest`. Убедитесь, что тесты проходят успешно при запуске из терминала командой `pytest`.\n",
        "\n",
        "Также выведите результат их выполнения в ячейке ниже.\n",
        "\n",
        "**Не забывайте про соблюдение PEP-8**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f66309c0",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lBFAw4b3z8QY",
      "metadata": {
        "id": "lBFAw4b3z8QY"
      },
      "outputs": [],
      "source": [
        "# Ячейка для демонстрации работоспособности\n",
        "# Сам код напишите в отдельном скрипте\n",
        "! pytest test/test_scraper.py"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cRSQlHfRtOdN",
      "metadata": {
        "id": "cRSQlHfRtOdN"
      },
      "source": [
        "## Задание 5. Оформление проекта на GitHub и работа с Git (35 баллов)\n",
        "\n",
        "В этом задании нужно воспользоваться системой контроля версий Git и платформой GitHub для хранения и управления своим проектом. **Ссылку на свой репозиторий пришлите в форме для сдачи ответа.**\n",
        "\n",
        "### Пошаговая инструкция и задания\n",
        "\n",
        "**1. Установите Git на свой компьютер.**\n",
        "\n",
        "* Для Windows: [скачайте установщик](https://git-scm.com/downloads) и выполните установку.\n",
        "* Для macOS:\n",
        "\n",
        "  ```\n",
        "  brew install git\n",
        "  ```\n",
        "* Для Linux:\n",
        "\n",
        "  ```\n",
        "  sudo apt update\n",
        "  sudo apt install git\n",
        "  ```\n",
        "\n",
        "**2. Настройте имя пользователя и email.**\n",
        "\n",
        "Это нужно для подписи ваших коммитов, сделайте в терминале через `git config ...`.\n",
        "\n",
        "**3. Создайте аккаунт на GitHub**, если у вас его еще нет:\n",
        "[https://github.com](https://github.com)\n",
        "\n",
        "**4. Создайте новый репозиторий на GitHub:**\n",
        "\n",
        "* Найдите кнопку **New repository**.\n",
        "* Укажите название, краткое описание, выберите тип **Public** (чтобы мы могли проверить ДЗ).\n",
        "* Не ставьте галочку Initialize this repository with a README.\n",
        "\n",
        "**5. Создайте локальную папку с проектом.** Можно в терминале, можно через UI, это не имеет значения.\n",
        "\n",
        "**6. Инициализируйте Git в этой папке.** Здесь уже придется воспользоваться некоторой командой в терминале.\n",
        "\n",
        "**7. Привяжите локальный репозиторий к удаленному на GitHub.**\n",
        "\n",
        "**8. Создайте ветку разработки.** По умолчанию вы будете находиться в ветке `main`, создайте и переключитесь на ветку `hw-books-parser`.\n",
        "\n",
        "**9. Добавьте в проект следующие файлы и папки:**\n",
        "\n",
        "* `scraper.py` — ваш основной скрипт для сбора данных.\n",
        "* `README.md` — файл с кратким описанием проекта:\n",
        "\n",
        "  * цель;\n",
        "  * инструкции по запуску;\n",
        "  * список используемых библиотек.\n",
        "* `requirements.txt` — файл со списком зависимостей, необходимых для проекта (не присылайте все из глобального окружения, создайте изолированную виртуальную среду, добавьте в нее все нужное для проекта и получите список библиотек через `pip freeze`).\n",
        "* `artifacts/` — папка с результатами парсинга (`books_data.txt` — полностью или его часть, если весь не поместится на GitHub).\n",
        "* `notebooks/` — папка с заполненным ноутбуком `HW_03_python_ds_2025.ipynb` и запущенными ячейками с выводами на экран.\n",
        "* `tests/` — папка с тестами на `pytest`, оформите их в формате скрипта(-ов) с расширением `.py`.\n",
        "* `.gitignore` — стандартный файл, который позволит исключить временные файлы при добавлении в отслеживаемые (например, `__pycache__/`, `.DS_Store`, `*.pyc`, `venv/` и др.).\n",
        "\n",
        "\n",
        "**10. Сделайте коммит.**\n",
        "\n",
        "**11. Отправьте свою ветку на GitHub.**\n",
        "\n",
        "**12. Создайте Pull Request:**\n",
        "\n",
        "* Перейдите в репозиторий на GitHub.\n",
        "* Нажмите кнопку **Compare & pull request**.\n",
        "* Укажите, что было добавлено, и нажмите **Create pull request**.\n",
        "\n",
        "**13. Выполните слияние Pull Request:**\n",
        "\n",
        "* Убедитесь, что нет конфликтов.\n",
        "* Нажмите **Merge pull request**, затем **Confirm merge**.\n",
        "\n",
        "**14. Скачайте изменения из основной ветки локально.**\n",
        "\n",
        "\n",
        "\n",
        "### Требования к итоговому репозиторию\n",
        "\n",
        "* Файл `scraper.py` с рабочим кодом парсера.\n",
        "* `README.md` с описанием проекта и инструкцией по запуску.\n",
        "* Папка `artifacts/` с результатом сбора данных (`.txt` файл).\n",
        "* Папка `tests/` с тестами на `pytest`.\n",
        "* Папка `notebooks/` с заполненным ноутбуком `HW_03_python_ds_2025.ipynb`.\n",
        "* Pull Request с комментарием из ветки `hw-books-parser` в ветку `main`.\n",
        "* Примерная структура:\n",
        "\n",
        "  ```\n",
        "  books_scraper/\n",
        "  ├── artifacts/\n",
        "  │   └── books_data.txt\n",
        "  ├── notebooks/\n",
        "  │   └── HW_03_python_ds_2025.ipynb\n",
        "  ├── scraper.py\n",
        "  ├── README.md\n",
        "  ├── tests/\n",
        "  │   └── test_scraper.py\n",
        "  ├── .gitignore\n",
        "  └── requirements.txt\n",
        "  ```"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dz3_venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
